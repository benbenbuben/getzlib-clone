import axios from 'axios';
import * as cheerio from 'cheerio';
import { Domain, DomainData } from '../types/domain';
import redis from '@/lib/redis';

const REDIS_KEY = 'zlib:domains';
const EXPIRE_SECONDS = 86400; // 1å¤©

async function crawlDomains(): Promise<DomainData> {
  try {
    console.log('[CRAWLER] Start crawling at', new Date().toISOString());
    const response = await axios.get('https://www.tboxn.com/sites/320.html');
    const $ = cheerio.load(response.data);

    const title = $('h2:contains("æœ€æ–°å®˜ç½‘åœ°å€")');
    console.log('[CRAWLER] h2:contains("æœ€æ–°å®˜ç½‘åœ°å€") found:', title.length);
    const domains: Domain[] = [];
    if (title.length > 0) {
      let next = title.next();
      let idx = 0;
      while (next.length && !/^h[23]$/i.test(next[0].tagName)) {
        // æŸ¥æ‰¾ strong æ ‡ç­¾ï¼Œspan è“è‰²ä¸”å†…å®¹åŒ…å«"ç¬¬ä¸‰æ–¹"æˆ–"å®˜æ–¹åœ°å€"
        next.find('strong').each((_, elem) => {
          const span = $(elem).find('span[style*="color: #0000ff"]');
          const label = span.text();
          if (/ç¬¬ä¸‰æ–¹|å®˜æ–¹åœ°å€/.test(label)) {
            // strong æ ‡ç­¾åé¢çš„æ–‡æœ¬èŠ‚ç‚¹
            const strongHtml = $(elem).html() || '';
            // strong ç»“æŸåå¯èƒ½ç›´æ¥è·Ÿç€ url æ–‡æœ¬ï¼Œä¹Ÿå¯èƒ½åœ¨ strong å†…éƒ¨
            // å…ˆå°è¯• strong æ ‡ç­¾å†…çš„æ–‡æœ¬
            const matchInner = strongHtml.match(/<span[^>]*>.*?<\/span>([^<ğŸ‘‰\s]+https?:\/\/[^ğŸ‘‰\s<]+)/);
            if (matchInner && matchInner[1]) {
              const url = matchInner[1].replace(/[ğŸ‘‰\s]+$/, '');
              if (!domains.some(d => d.url === url)) {
                domains.push({
                  url,
                  status: 'active',
                  lastChecked: new Date().toISOString(),
                  source: 'crawler',
                  note: label.replace(/[:ï¼š]/g, '')
                });
                console.log('[CRAWLER] Add domain:', url, 'label:', label);
              }
            } else {
              // strong æ ‡ç­¾åé¢çš„æ–‡æœ¬èŠ‚ç‚¹
              const nextNode = elem.nextSibling;
              if (nextNode && nextNode.type === 'text') {
                const text = nextNode.data;
                const match = text.match(/https?:\/\/[^ğŸ‘‰\s<]+/);
                if (match) {
                  const url = match[0].replace(/[ğŸ‘‰\s]+$/, '');
                  if (!domains.some(d => d.url === url)) {
                    domains.push({
                      url,
                      status: 'active',
                      lastChecked: new Date().toISOString(),
                      source: 'crawler',
                      note: label.replace(/[:ï¼š]/g, '')
                    });
                    console.log('[CRAWLER] Add domain:', url, 'label:', label);
                  }
                }
              }
            }
          }
        });
        next = next.next();
        idx++;
      }
    } else {
      console.log('[CRAWLER] æœªæ‰¾åˆ° h2:contains("æœ€æ–°å®˜ç½‘åœ°å€")');
    }

    const data = {
      domains,
      lastUpdated: new Date().toISOString()
    };
    console.log('[CRAWLER] ç²¾å‡†çˆ¬å–åˆ°çš„åŸŸå:', domains);

    // ç›´æ¥æ›´æ–° Redisï¼Œä¸å†å†™å…¥æœ¬åœ°æ–‡ä»¶
    try {
      await redis.set(REDIS_KEY, JSON.stringify(data), 'EX', EXPIRE_SECONDS);
      console.log('[CRAWLER] Redis update success');
    } catch (error) {
      console.error('[CRAWLER] Redis update error:', error);
    }

    return data;
  } catch (error) {
    console.error('[CRAWLER] çˆ¬è™«è·å–å¤±è´¥:', error);
    // å¦‚æœçˆ¬å–å¤±è´¥ï¼Œå°è¯•ä» Redis è·å–æ•°æ®
    try {
      const cached = await redis.get(REDIS_KEY);
      if (cached) {
        const parsed = JSON.parse(cached);
        console.log('[CRAWLER] Fallback to Redis cached data');
        return parsed;
      }
    } catch (e) {
      console.error('[CRAWLER] Redis fallback error:', e);
    }
    // å¦‚æœ Redis ä¹Ÿæ²¡æœ‰æ•°æ®ï¼Œè¿”å›ç©ºæ•°æ®
    return {
      domains: [],
      lastUpdated: new Date().toISOString()
    };
  }
}

export { crawlDomains }; 